{Charmworks, Inc. $\>$$\>$$\>$$\>$Software Developer$\>$$\>$$\>$$\>$Jun '18 - present}
\begin{itemize}
\item Integrating a shared memory library for sophisticated loop scheduling strategies, with some
strategies being based on strategies I’ve developed for my dissertation, into the current version
of Charm++.
\item Comparing performance of a loop scheduling strategy available in the integrated shared memory library with the performance of the corresponding loop scheduling strategy available in LLVM’s OpenMP library.
\item Providing feedback for tutorials on Charm++ to improve them.
\end{itemize} 

{University of Southern California$\>$$\>$$\>$$\>$Computer Scientist$\>$$\>$$\>$$\>$Dec. '16 - Jun '18}
\vspace*{-0.0in} 
\begin{itemize}
\item Working with postdoc from LLNL on a proposal to study
techniques that combine loop scheduling and load balancing to improve
performance of scientific applications.
\item Working with OpenMP Language Committee to support
\url{https://sites.google.com/site/userdefschedopenmp}[user-defined schedules] in OpenMP.
\item Translating an x-ray tomography code written in
Matlab code to C code and then parallelizing it to run on a supercomputer
having nodes with GPGPUs. 
\item Working on modifications to LLVM compiler to support new
OpenMP loop schedules. 
\item Worked on ensuring external network infrastructure to support transfer of application code's input data files were adequate
for an application code's efficient execution using the Globus Toolkit.
%\item \small Managing a git repository for a team working on
%performance optimizations of the application program.
\item Working in team to manage computational performance aspects of running an application program involving Fast Fourier Transformation and image reconstruction algorithms. 
%\item \small Doing optimizations for MPI+CUDA application code involving low-overhead loop scheduling and loop optimizations such as loop unrolling. 
%\item \small Working on transformations in LLVM. 
\end{itemize}

%TODO: adaptive VS hybrid VS ... 
{\small Charmworks, Inc.$\>$$\>$$\>$$\>$Developer$\>$$\>$$\>$$\>$Jan. '16 - Nov. '16}
\vspace*{-0.0in}
\begin{itemize}
\item Implemented mixed static/dynamic loop scheduling
strategies within Charm++'s thread scheduling library.
%TODO: consider adding 'including in cloud environments' the end of
%the sentence. 
%TODO: make paragraph 
\item Helped to improve portability of Charm++ to a variety of platforms. 
\item Assisted with business aspects of a high-tech startup. 
\end{itemize} 

{ University of Illinois$\>$$\>$$\>$$\>$Postdoctoral Associate$\>$$\>$$\>$$\>$Jul. '15 – Dec. '15}
\vspace*{-0.0in}
\begin{itemize} 
\item Developed library that allows application programmers to use strategies from dissertation.
\item Adapted a plasma physics application code to work on a
GPGPU processor and Intel Xeon Phi.
\item Incorporated over-decomposition and locality-aware scheduling into strategies from dissertation.
\end{itemize}

{Lawrence Livermore Nat’l Lab$\>$$\>$$\>$$\>$Lawrence Scholar$\>$$\>$$\>$$\>$Feb. '12 – Jun. '14}
\vspace*{-0.0in}
\begin{itemize} 
\item Measured MPI communication delays for micro-benchmarks codes run on supercomputers and worked to find tools to measure dequeue overheads of OpenMP loop schedulers.
\item Created a software system for automated performance optimization and application programmer usability of low-overhead hybrid scheduling
strategies.
\item Developed a ROSE-based custom compiler for automatically transforming MPI+OpenMP applications to use low-overhead scheduling
techniques and runtime.
\item Assessed further opportunities for performance improvement of low-overhead schedulers, including improvement of spatial locality
of low-overhead schedulers.
\end{itemize}

{Lawrence Livermore Nat’l Lab$\>$$\>$$\>$$\>$Scholar$\>$$\>$$\>$$\>$Jun. '11 - Sep. '11}
\vspace*{-0.0in}
\begin{itemize} 
\item Experimented with different OpenMP parameters of implemented MPI+OpenMP application code to understand performance optimizations on
LLNL supercomputers.
\item Developed software design for low-overhead loop scheduling library based on libgomp software design.
\end{itemize} 

{Lawrence Berkeley Nat’l Lab$\>$$\>$$\>$$\>$Summer Scholar$\>$$\>$$\>$$\>$Aug. '10 - Sep. '10}
\begin{itemize}
\item Analyzed results for the performance tests developed on NERSC machines.
\item compared with collectives in reference to MPI (mpich2) runtime system.
\end{itemize}

{Lawrence Livermore Nat’l Lab$\>$$\>$$\>$$\>$Scholar$\>$$\>$$\>$$\>$May. '10 - Aug. '10}
\begin{itemize}
\item Modified libgomp runtime system in order to integrate low-overhead schedulers within it.
\item Developed an algorithm multi-stage low-overhead loop scheduler with each stage associated with a level in the memory hierarchy, allowing for MPI-shared memory extensions to be used in conjunction with the low-overhead loop scheduling strategies.
\end{itemize}
{Goldman-Sachs$\>\>\>\>$Summer Analyst$\>\>\>\>$Jun. ‘09 – Sep. ‘09}
\vspace*{-0.0in}
\begin{itemize}
\item Wrote code for testing trading system infrastructure functions under extreme market conditions.
\item Analyzed performance bottlenecks of system infrastructure functions.
\end{itemize}
